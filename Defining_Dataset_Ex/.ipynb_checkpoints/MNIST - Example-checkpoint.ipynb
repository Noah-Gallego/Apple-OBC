{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Pre-Defined Dataset\n",
    "\n",
    "This notebooks demonstrates how a PyTorch data-loading pipeline works, which is in three steps:\n",
    "\n",
    "1. **Load / create train and test data**: Load a dataset into PyTorch, and define separate train and test sets\n",
    "2. **Visualize**: Inspect the dataset\n",
    "3. **Create DataLoaders**: Create train and test DataLoaders that allow you to create batches of data and perform other, useful operations\n",
    "\n",
    "You're encouraged to change and add to this notebook to further explore the pre-defined, MNIST dataset, or to train a hand-written digit classifier of your own! There is no assignment or submission associated with this exploration.\n",
    "\n",
    "I'll start with the usual PyTorch imports, including an import statement for PyTorch's pre-defined vision datasets, `from torchvision import datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Load MNIST Train/Test Datasets\n",
    "\n",
    "PyTorch provides a way to load separate train and test MNIST datasets, as specified in the [dataset documentation](https://pytorch.org/vision/stable/datasets.html#mnist), with the parameter `train` being set to True or False. \n",
    "\n",
    "Some datasets are loaded all at once, such that you may have to take an additional step to randomly split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1131)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1131)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1131)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1131)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data\n",
    "\n",
    "You should see more training than test data; specifically 60k and 10k samples, and each data point should hold one grayscale image and a corresponding class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MNIST training examples: 60000\n",
      "Number of MNIST test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of MNIST training examples: {}\".format(len(mnist_train)))\n",
    "print(\"Number of MNIST test examples: {}\".format(len(mnist_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default image shape: torch.Size([1, 28, 28])\n",
      "Reshaped image shape: torch.Size([28, 28])\n",
      "The label for this image: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the first training example\n",
    "rand = random.randint(0, len(mnist_train))\n",
    "image, label = mnist_train[rand]\n",
    "\n",
    "# reshape the image back to 28x28 pixels\n",
    "print(\"Default image shape: {}\".format(image.shape))\n",
    "image = image.reshape([28,28])\n",
    "print(\"Reshaped image shape: {}\".format(image.shape))\n",
    "\n",
    "# plot the image\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "# print the label\n",
    "print(\"The label for this image: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders\n",
    "\n",
    "The next step that Iâ€™ll take is wrapping my training and test datasets in PyTorch DataLoaders. \n",
    "\n",
    "> DataLoaders allow you to split our dataset into appropriate batches, shuffle your data, and perform other operations before it is fed into a neural net.\n",
    "\n",
    "You can read about data loading abilities in PyTorch in the [data documentation](https://pytorch.org/docs/stable/data.html).\n",
    "\n",
    "Try completing this code yourself, with the following arguments:\n",
    "* `batch_size = 128` for _both_ training and test DataLoaders\n",
    "* `shuffle = True` for _only_ the training DataLoader\n",
    "\n",
    "**A note on these parameters**: \n",
    "* What do you think a _good_ batch size is? This is how many data points a model sees during a single training step (one _epoch_ over an entire dataset may take thousands of such steps); an error is calculated on a batch of data and the weights of an NN are updated in response. \n",
    "* Why do you think it would be useful to _shuffle_ some training data (but not test data)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(mnist_train, batch_size = 128, shuffle = True)\n",
    "test_dl = DataLoader(mnist_test, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## free space: explore on your own! \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class create_model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(create_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_model(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 28**2\n",
    "hidden_dim = 128\n",
    "output_dim = 10\n",
    "\n",
    "model = create_model(input_dim, output_dim, hidden_dim)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 2.3022856437829513\n",
      "Epoch [2/15], Loss: 2.2899053630544177\n",
      "Epoch [3/15], Loss: 2.2761034284319197\n",
      "Epoch [4/15], Loss: 2.260146065307324\n",
      "Epoch [5/15], Loss: 2.2402163156822548\n",
      "Epoch [6/15], Loss: 2.215832831763001\n",
      "Epoch [7/15], Loss: 2.18413498762574\n",
      "Epoch [8/15], Loss: 2.144005786635474\n",
      "Epoch [9/15], Loss: 2.0941707859161314\n",
      "Epoch [10/15], Loss: 2.029631959604048\n",
      "Epoch [11/15], Loss: 1.952115973684071\n",
      "Epoch [12/15], Loss: 1.8581600580642472\n",
      "Epoch [13/15], Loss: 1.7550166438637511\n",
      "Epoch [14/15], Loss: 1.6454061216382838\n",
      "Epoch [15/15], Loss: 1.5296818960958452\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_dl:\n",
    "        # Flatten MNIST images into a 784-dimensional vector\n",
    "        images = images.view(images.size(0), -1)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        # Print loss (optional)\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_dl)}\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 70.82%\n",
      "Predicted: 7 - Actual: 7\n",
      "Predicted: 3 - Actual: 3\n",
      "Predicted: 0 - Actual: 0\n",
      "Predicted: 9 - Actual: 4\n",
      "Predicted: 9 - Actual: 9\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        for images, labels in data_loader:\n",
    "            # Flatten MNIST images into a 784-dimensional vector\n",
    "            images = images.view(images.size(0), -1)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Get the predicted class by taking the index of the maximum value in the output tensor\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Total number of labels\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            # Count the number of correct predictions\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store all predictions and labels\n",
    "            all_preds.extend(predicted.cpu().numpy())  # Collect all predicted values\n",
    "            all_labels.extend(labels.cpu().numpy())    # Collect actual labels\n",
    "\n",
    "    # Calculate accuracy as (correct / total)\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, all_preds, all_labels\n",
    "\n",
    "# Test the model and print accuracy\n",
    "test_accuracy, predictions, labels = calculate_accuracy(model, test_dl)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "# Optionally, print the first few predicted and actual labels for verification\n",
    "for i in range(5):  # Example: print first 5\n",
    "    print(f\"Predicted: {predictions[i]} - Actual: {labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
