{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction To Tensors\n",
    "\n",
    "All deep learning frameworks work with **tensors**, which are multidimensional arrays of data. \n",
    "\n",
    "Deep learning, at its core, is just manipulating tensors. \n",
    "\n",
    "### Goals\n",
    "\n",
    "In this notebook, the main goal is for you to:\n",
    "* Gain familiarity with creating and manipulating tensors in PyTorch.\n",
    "\n",
    "When the notebook is complete, submit it for grading!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1:\n",
    "\n",
    "Import the base torch library. \n",
    "\n",
    "Create a 3x3 tensor filled with ones. \n",
    "\n",
    "Output should look like below:\n",
    "```\n",
    "tensor([[1., 1., 1.],\n",
    "        [1., 1., 1.],\n",
    "        [1., 1., 1.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.ones(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2:\n",
    "\n",
    "Create a 5x5 tensor filled with 0's\n",
    "\n",
    "Output should look like below:\n",
    "```\n",
    "tensor([[0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3:\n",
    "\n",
    "Create a 4x4 tensor filled with random numbers between 0 and 1\n",
    "\n",
    "Output should look like below:\n",
    "```\n",
    "tensor([[0.0815, 0.5265, 0.8874, 0.0686],\n",
    "        [0.3006, 0.8532, 0.8465, 0.8843],\n",
    "        [0.5484, 0.6343, 0.0828, 0.3912],\n",
    "        [0.8559, 0.0851, 0.8944, 0.9473]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7482, 0.5038, 0.3292, 0.7258],\n",
       "        [0.3814, 0.4681, 0.2917, 0.9834],\n",
       "        [0.1676, 0.0823, 0.3597, 0.3785],\n",
       "        [0.2475, 0.6609, 0.7187, 0.9735]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4:\n",
    "\n",
    "Create a 6x3 tensor filled with random numbers sampled from a normal distribution with mean 0 and variance 1.\n",
    "Sampling from a normal distribution is a common way to **initialize the weights** of a neural network. \n",
    "\n",
    "Such a tensor could be used to initialize the weights of a single-layer NN with 6 input features and 3 model outputs. \n",
    "\n",
    "Output should look like below:\n",
    "```\n",
    "tensor([[-0.2884, -1.1581, -0.3374],\n",
    "        [ 1.2560,  1.1639, -1.4499],\n",
    "        [-2.7369, -2.1460, -0.4664],\n",
    "        [ 0.3202, -0.3646,  0.0976],\n",
    "        [ 0.4570, -0.4369, -0.9742],\n",
    "        [-1.0214,  0.1527,  0.8966]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3484,  0.0442, -1.5182],\n",
       "        [ 1.7068,  0.3684, -1.5832],\n",
       "        [-0.6877, -0.9322, -0.7658],\n",
       "        [ 1.8337, -0.2093,  0.9767],\n",
       "        [-2.1838,  0.2123, -1.6571],\n",
       "        [-0.5160,  0.5275,  0.3150]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(6, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5:\n",
    "\n",
    "Print out the shape of the following tensor torch.ones(3, 3, 8)\n",
    "\n",
    "Output should look like below:\n",
    "```\n",
    "torch.Size([3, 3, 8])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = torch.ones(3, 3, 8)\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6:\n",
    "\n",
    "Flatten the tensor of ones you made above, and check the shape again. Flattening is often useful for passing in 1D vectors of values as input to a simple neural net.\n",
    "\n",
    "Output should look like below:\n",
    "```\n",
    "torch.Size([72])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(n).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7:\n",
    "\n",
    "Create a random tensor. Add a dimension of size 1 inserted at dimension 0\n",
    "\n",
    "Output should look something like below:\n",
    "```\n",
    "tensor([[[0.3769, 0.8775, 0.6167, 0.8245],\n",
    "         [0.6709, 0.8618, 0.9430, 0.1272],\n",
    "         [0.6014, 0.6074, 0.6148, 0.5054],\n",
    "         [0.8542, 0.8872, 0.8324, 0.6358]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4937, 0.0333, 0.6212, 0.8847],\n",
       "         [0.7561, 0.8064, 0.2457, 0.5942],\n",
       "         [0.8013, 0.0570, 0.6249, 0.4447],\n",
       "         [0.0672, 0.2309, 0.7093, 0.0620]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.rand(4, 4)\n",
    "r.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8: \n",
    "\n",
    "Remove the dimension that you just added in the previous question\n",
    "\n",
    "Output should look like below:\n",
    "```\n",
    "tensor([[0.3769, 0.8775, 0.6167, 0.8245],\n",
    "        [0.6709, 0.8618, 0.9430, 0.1272],\n",
    "        [0.6014, 0.6074, 0.6148, 0.5054],\n",
    "        [0.8542, 0.8872, 0.8324, 0.6358]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4937, 0.0333, 0.6212, 0.8847],\n",
       "        [0.7561, 0.8064, 0.2457, 0.5942],\n",
       "        [0.8013, 0.0570, 0.6249, 0.4447],\n",
       "        [0.0672, 0.2309, 0.7093, 0.0620]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9:\n",
    "\n",
    "Create a tensor of size (3,4). Stack four copies of the tensor together\n",
    "\n",
    "Output should look like below:\n",
    "```\n",
    "tensor([[[0.0576, 0.7126, 0.9228, 0.6803],\n",
    "         [0.3462, 0.2544, 0.3844, 0.5083],\n",
    "         [0.0428, 0.5889, 0.3554, 0.2517]],\n",
    "\n",
    "        [[0.0576, 0.7126, 0.9228, 0.6803],\n",
    "         [0.3462, 0.2544, 0.3844, 0.5083],\n",
    "         [0.0428, 0.5889, 0.3554, 0.2517]],\n",
    "\n",
    "        [[0.0576, 0.7126, 0.9228, 0.6803],\n",
    "         [0.3462, 0.2544, 0.3844, 0.5083],\n",
    "         [0.0428, 0.5889, 0.3554, 0.2517]],\n",
    "\n",
    "        [[0.0576, 0.7126, 0.9228, 0.6803],\n",
    "         [0.3462, 0.2544, 0.3844, 0.5083],\n",
    "         [0.0428, 0.5889, 0.3554, 0.2517]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7349, 0.2667, 0.2582, 0.3289],\n",
       "         [0.8233, 0.5489, 0.9220, 0.8990],\n",
       "         [0.3771, 0.6232, 0.9536, 0.6524]],\n",
       "\n",
       "        [[0.7349, 0.2667, 0.2582, 0.3289],\n",
       "         [0.8233, 0.5489, 0.9220, 0.8990],\n",
       "         [0.3771, 0.6232, 0.9536, 0.6524]],\n",
       "\n",
       "        [[0.7349, 0.2667, 0.2582, 0.3289],\n",
       "         [0.8233, 0.5489, 0.9220, 0.8990],\n",
       "         [0.3771, 0.6232, 0.9536, 0.6524]],\n",
       "\n",
       "        [[0.7349, 0.2667, 0.2582, 0.3289],\n",
       "         [0.8233, 0.5489, 0.9220, 0.8990],\n",
       "         [0.3771, 0.6232, 0.9536, 0.6524]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.rand(3, 4)\n",
    "torch.stack([r, r, r, r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 10:\n",
    "\n",
    "Something is wrong with the matrix multiplication code below. \n",
    "> Importantly tensor multiplication and tensor _matrix_ multiplication are different operations; try out the `mul()` and `matmul()` operations to see the difference. You can also refer to the [PyTorch documentation on matmul](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "Matrix multiplication does a multiplication and sum operation according to the values in the rows of the _first_ matrix and the _columns_ of the second, which means the dimension of those rows and columns should match, as explained in [this short blog post](https://www.mathsisfun.com/algebra/matrix-multiplying.html). \n",
    "\n",
    "Fix the code below so that you can matmul tensors `x` and `W` and get 3 output values.\n",
    "\n",
    "Output should look similar to below:\n",
    "```\n",
    "tensor([[ 0.0885,  1.4044, -2.5051]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4061, -0.2037,  1.0271]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights\n",
    "W = torch.randn(6, 3)\n",
    "b = torch.randn(1, 3)\n",
    "\n",
    "# 6 random inputs\n",
    "x = torch.rand(1, 6)\n",
    "\n",
    "out = torch.matmul(x, W) + b\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
